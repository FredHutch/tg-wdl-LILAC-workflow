---
title: "DuelingBanjos"
author: "Amy Paguirigan"
date: "04/15/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Install Required Packages
```{r}
remotes::install_github('FredHutch/tgR')
remotes::install_github('FredHutch/fh.wdlR')
```

# Load Packages
```{r}
library(tidyverse); library(tgR); library(fh.wdlR)
```

# Set Credentials
```{r}
setCreds(path = "~/github/cred/paguirigan.R") 
```

# Pull S3 Inventory and Annotate
```{r}
bucket <- "fh-pi-berger-a"; DAG  <- "bergera"
tags <- listS3Objects(bucket = bucket)
annotations <- tgrAnnotate(DAG = DAG, harmonizedOnly = FALSE)
monsterMash <- dplyr::left_join(tags, annotations) %>% dropWhen()
```

# Filter Inventory for Workflow Input Data
In this workflow, the input data must be unmapped bams with quality control checks.  Also, to run the workflow you'll need the bed file for the dataset up in S3.  
```{r}
unique(monsterMash$workflowName)
unmappedBams <- monsterMash %>% 
  filter(workflowName %in% c("AlignedToUnMappedBam", "PairedFastqsToUnmappedBam") & 
           genomics_type == "dnaseq" & 
           workflowOutputType == "unmappedbam") %>% dropWhen(unique = T)

unmappedBams %>% group_by(workflowOutputType) %>%summarize(n())
pairedSamples <- unmappedBams %>% 
  select(molecular_id, omics_sample_name, key, seq_libtype, 
         tissue_type, biospecimen_id, subject_id) %>% 
  filter(molecular_id != "referenceDataSet")

```

# Match Sample and Reference Datasets
```{r}
samples <- pairedSamples %>% filter(tissue_type == "lung") %>% 
  select(key, omics_sample_name, subject_id, molecular_id) %>%
  rename("sampleBamLocation" = "key", "sampleName" = "omics_sample_name")

references <- pairedSamples %>% filter(tissue_type == "peripheralblood") %>% 
  select(key, omics_sample_name, subject_id, molecular_id) %>% 
  rename("refBamLocation" = "key", "referenceName" = "omics_sample_name", "ref_molecular_id" = "molecular_id")

matched <- inner_join(samples, references, by = "subject_id") %>% filter(subject_id != "blinded")# Check here that all is as it should be.  
matched$sampleBamLocation <- paste0("s3://fh-pi-berger-a/", matched$sampleBamLocation)
matched$refBamLocation <- paste0("s3://fh-pi-berger-a/", matched$refBamLocation)
matched$bedLocation <- "s3://fh-pi-paguirigan-a-genomicsrepo/repoReferenceData/bedFiles/dfci-v5Oncopanel3.1/Exome_Plus_POPv3.1_SV_ONLY_3191451_Covered_hg19-tabbed.bed"

```

# Prefilter manifest if needed
```{r}
manifest <- matched
manifest <- manifest[1,]
```

# Name and Ship Batch File
```{r}
batchFileName <- paste0("cromwell-manifests/",format(Sys.Date(), "%Y-%m-%d-"), "duel-hg19-withstrelka.tsv")
paste0("s3://fh-pi-paguirigan-a-genomicsrepo/", batchFileName)
s3write_using(manifest,
              FUN = write.table, quote = F, row.names = F, sep = "\t",
              object = batchFileName,
              bucket = "fh-pi-paguirigan-a-genomicsrepo")
thisManifest <- "cromwell-manifests/2019-12-09-duel-hg19-withstrelka.tsv"
```
# Kick off your server and set the URL as an environment variable for this session
```{r}
cromwellCreate(FredHutchId = "apaguiri", port = "1981",
        pathToServerLogs = " ~/cromwell/partlyCloudyConfig/server-logs/partly-v49-%A.txt",
        pathToServerScript = "~/cromwell/partlyCloudyConfig/partlyCloudy.sh",
        pathToParams = "~/cromwell/partlyCloudyConfig/cromwellParams.sh")

setCromwellURL(FredHutchId = "apaguiri", jobId = "47006887", port = "8000")

Sys.setenv("CROMWELLURL" = "http://gizmoj20:8000")
Sys.getenv("CROMWELLURL")
```
# Validate workflow
```{r}
valid <- womtoolValidate(WDL = "duelingBanjos_GATK4.1.0.0.wdl"); valid[["errors"]]; valid$isRunnableWorkflow
```


# Submit Job to Cromwell
Note: setwd to location of workflow files
```{r}
thisJob <- cromwellSubmitBatch(WDL = "duelingBanjos_GATK4.1.0.0.wdl",
                    Params = "duel_parameters_4.1.0.0_hg19.json",
                    Batch = "duel_batch.json",
                    Options = "workflow-options.json",
                    Labels = data.frame("workflowType" = ""))
thisOne <- thisJob$id; thisOne
```


# See all the  jobs this server has run in the past (x) days
```{r}
afew <- 1
jobs <- cromwellJobs(days = afew) %>% arrange(desc(start))
```

# Isolate one workflow
```{r}
thisOne <- jobs$workflow_id[1]
```

# Monitor Running Workflows
```{r}
w <- cromwellWorkflow(thisOne); w$status
c <- cromwellCall(thisOne); c %>% group_by(executionStatus, callName) %>% summarize(status = n())
ca <- cromwellCache(thisOne); ca %>% group_by(callCaching.hit, callName) %>% summarize(hits = n())
f <- cromwellFailures(thisOne); f
```

# Find out more about call caching and calls
```{r}
butWhy <- left_join(cromwellCall(thisOne) %>% mutate_all(as.character), 
                    cromwellCache(thisOne) %>% mutate_all(as.character)); butWhy %>% group_by(callName, executionStatus, callCaching.hit) %>% summarize(hits = n()) %>% arrange(desc(executionStatus))
```

# Stop a workflow or find more about it
```{r}
abort <- cromwellAbort(thisOne)
WTF <- cromwellGlob(thisOne); WTF$failures
cromwellTiming(thisOne)
```

# Output Handling
```{r}
out <- cromwellOutputs(thisOne) 
```

See CopyNTag wdl workflow to deposit and tag data.  






